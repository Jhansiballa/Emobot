ğŸ¤– EMOBOT â€“ Emotion Detecting Chatbot

An AI-powered chatbot that understands human emotions and responds empathetically.
Built with Flask, PyTorch, and BERT, EMOBOT provides personalized, engaging conversations while promoting emotional well-being.

ğŸŒŸ Features

ğŸ” Emotion Detection â€“ Detects joy, sadness, anger, fear, surprise, love, neutral from user text using pretrained BERT.

ğŸ’¬ Interactive Chatbot â€“ Generates empathetic and human-like responses.

ğŸ­ Emotion-based Actions â€“ Displays dynamic buttons like:

Joy â†’ Play a game

Sadness â†’ Suggest a book or meme

Fear â†’ Relaxation techniques

Love â†’ Love songs on Spotify

Surprise â†’ Explore Wikipedia

ğŸ“œ Conversation Memory â€“ Maintains chat history with Flask sessions.

ğŸŒ User-Friendly UI â€“ Responsive HTML/CSS + JavaScript interface.

ğŸ› ï¸ Tech Stack

Backend: Flask, Flask-CORS, Python

AI Model: HuggingFace Transformers (nateraw/bert-base-uncased-emotion) + PyTorch

Frontend: HTML5, CSS3, Vanilla JavaScript

Database (optional): Flask session (in-memory)

ğŸ“‚ Repository Structure
emobot-chatbot/
â”‚â”€â”€ app.py                # Flask backend (API + chatbot logic)
â”‚â”€â”€ requirements.txt       # Dependencies
â”‚â”€â”€ templates/
â”‚   â””â”€â”€ index.html         # Chat UI
â”‚â”€â”€ static/
â”‚   â””â”€â”€ script.js          # Frontend logic (fetch + dynamic buttons)
â”‚â”€â”€ README.md              # Project overview
â”‚â”€â”€ LICENSE                # MIT License
â”‚â”€â”€ .gitignore             # Ignore Python/env files
â”‚â”€â”€ MINI_PROJECT_FINAL.pdf # Detailed project report

ğŸš€ Getting Started
1. Clone the repo
git clone https://github.com/<your-username>/emobot-chatbot.git
cd emobot-chatbot

2. Create virtual environment
python -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate      # Windows

3. Install dependencies
pip install -r requirements.txt

4. Run the Flask server
python app.py

5. Open in browser

Go to â†’ http://127.0.0.1:5000

ğŸ“¡ API Usage
Endpoint: POST /chat

Request:

{ "message": "I am feeling happy today" }


Response:

{ 
  "reply": "Thatâ€™s amazing! Tell me more about whatâ€™s making you happy! ğŸ˜Š", 
  "emotion": "joy" 
}

ğŸ“– Future Scope

ğŸ™ï¸ Voice & Facial Emotion Detection for richer interaction.

ğŸŒ Multi-language Support for wider accessibility.

ğŸ•¶ï¸ AR/VR Integration for immersive emotional support.

ğŸ¤ Integration into mental health apps for real-world impact.

ğŸ‘©â€ğŸ’» Author

Jhansi Balla
B.Tech â€“ Information Technology (4th Year)
MVGR College of Engineering


